{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmrjJGFLCEPW8bfuxplDeq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yms07/My-Project1/blob/main/TestingModel_UsingAES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVkBD3k6N63A",
        "outputId": "edb095b6-b557-44bd-8912-04e112357d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =====================================\n",
        "# STEP 0: Mount Google Drive\n",
        "# =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Ransomware Detection Full Colab Notebook (Steps 4-6 + K-Fold CV)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Paths\n",
        "base_path = '/content/drive/MyDrive/ransomware_data'\n",
        "plain_csv = f'{base_path}/features_plaintext.csv'\n",
        "infect_csv = f'{base_path}/features_infected.csv'\n",
        "\n",
        "# Load data\n",
        "plain_df = pd.read_csv(plain_csv)\n",
        "infect_df = pd.read_csv(infect_csv)\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([plain_df, infect_df], ignore_index=True)\n",
        "\n",
        "# Convert timestamps to numeric\n",
        "for col in ['modified_time', 'access_time', 'created_time']:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    df[col] = df[col].astype('int64') / 1e9\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "print(\"✅ Dataset loaded and cleaned\")\n",
        "\n",
        "# All models\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'MLP': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "def kfold_train_and_evaluate(X, y, label):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    print(f\"\\n🧪 K-Fold Evaluation for {label}:\")\n",
        "\n",
        "    for name, model in models.items():\n",
        "        acc_list, prec_list, rec_list, f1_list, auc_list = [], [], [], [], []\n",
        "\n",
        "        for train_idx, test_idx in skf.split(X_scaled, y):\n",
        "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "            acc_list.append(accuracy_score(y_test, y_pred))\n",
        "            prec_list.append(precision_score(y_test, y_pred))\n",
        "            rec_list.append(recall_score(y_test, y_pred))\n",
        "            f1_list.append(f1_score(y_test, y_pred))\n",
        "            if y_prob is not None:\n",
        "                auc_list.append(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "        avg_acc = sum(acc_list) / len(acc_list)\n",
        "        avg_prec = sum(prec_list) / len(prec_list)\n",
        "        avg_rec = sum(rec_list) / len(rec_list)\n",
        "        avg_f1 = sum(f1_list) / len(f1_list)\n",
        "        avg_auc = sum(auc_list) / len(auc_list) if auc_list else None\n",
        "\n",
        "        print(f\"\\n📊 Model: {name}\")\n",
        "        print(f\"Accuracy : {avg_acc:.4f}\")\n",
        "        print(f\"Precision: {avg_prec:.4f}\")\n",
        "        print(f\"Recall   : {avg_rec:.4f}\")\n",
        "        print(f\"F1 Score : {avg_f1:.4f}\")\n",
        "        print(f\"AUC      : {avg_auc:.4f}\" if avg_auc else \"AUC      : N/A\")\n",
        "\n",
        "# ===============================\n",
        "# Run for all 3 feature combinations\n",
        "# ===============================\n",
        "\n",
        "y = df['label']\n",
        "\n",
        "# Dataset 1: entropy + file_type\n",
        "X1 = df[['entropy', 'file_type']]\n",
        "kfold_train_and_evaluate(X1, y, \"Dataset 1 (entropy + file_type)\")\n",
        "\n",
        "# Dataset 2: entropy + file_type + size\n",
        "X2 = df[['entropy', 'file_type', 'size']]\n",
        "kfold_train_and_evaluate(X2, y, \"Dataset 2 (entropy + file_type + size)\")\n",
        "\n",
        "# Dataset 3: entropy + file_type + size + MAC times\n",
        "X3 = df[['entropy', 'file_type', 'size', 'modified_time', 'access_time', 'created_time']]\n",
        "kfold_train_and_evaluate(X3, y, \"Dataset 3 (entropy + file_type + size + MAC times)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFJPkoLuYQVl",
        "outputId": "9a375972-c6f8-44a4-9f14-472730069129"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded and cleaned\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 1 (entropy + file_type):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 0.9950\n",
            "Precision: 0.9975\n",
            "Recall   : 0.9972\n",
            "F1 Score : 0.9974\n",
            "AUC      : 0.9984\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 0.9422\n",
            "Precision: 0.9422\n",
            "Recall   : 1.0000\n",
            "F1 Score : 0.9703\n",
            "AUC      : 0.9146\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 0.9944\n",
            "Precision: 0.9973\n",
            "Recall   : 0.9968\n",
            "F1 Score : 0.9970\n",
            "AUC      : 0.9763\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 0.9945\n",
            "Precision: 0.9973\n",
            "Recall   : 0.9969\n",
            "F1 Score : 0.9971\n",
            "AUC      : 0.9984\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 0.9952\n",
            "Precision: 0.9977\n",
            "Recall   : 0.9971\n",
            "F1 Score : 0.9974\n",
            "AUC      : 0.9995\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 0.9926\n",
            "Precision: 0.9984\n",
            "Recall   : 0.9938\n",
            "F1 Score : 0.9961\n",
            "AUC      : 0.9966\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 0.9937\n",
            "Precision: 0.9982\n",
            "Recall   : 0.9950\n",
            "F1 Score : 0.9966\n",
            "AUC      : 0.9994\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 2 (entropy + file_type + size):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 0.9961\n",
            "Precision: 0.9980\n",
            "Recall   : 0.9978\n",
            "F1 Score : 0.9979\n",
            "AUC      : 0.9977\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 0.9422\n",
            "Precision: 0.9422\n",
            "Recall   : 1.0000\n",
            "F1 Score : 0.9703\n",
            "AUC      : 0.9266\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 0.9982\n",
            "Precision: 0.9990\n",
            "Recall   : 0.9991\n",
            "F1 Score : 0.9990\n",
            "AUC      : 0.9915\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 0.9992\n",
            "Precision: 0.9998\n",
            "Recall   : 0.9994\n",
            "F1 Score : 0.9996\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 0.9983\n",
            "Precision: 0.9995\n",
            "Recall   : 0.9987\n",
            "F1 Score : 0.9991\n",
            "AUC      : 0.9999\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 0.9936\n",
            "Precision: 0.9983\n",
            "Recall   : 0.9949\n",
            "F1 Score : 0.9966\n",
            "AUC      : 0.9951\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 0.9936\n",
            "Precision: 0.9982\n",
            "Recall   : 0.9950\n",
            "F1 Score : 0.9966\n",
            "AUC      : 0.9988\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 3 (entropy + file_type + size + MAC times):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Final training for RandomForest with Dataset 2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Features same as best Dataset 2\n",
        "X = df[['entropy', 'file_type', 'size']]\n",
        "y = df['label']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "print(\"✅ Final model and scaler saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwZD78BCUEeF",
        "outputId": "fbf01075-4684-421b-9e0f-2859b017b9ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final model and scaler saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import math\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Use your same calculate_entropy & FILE_TYPE_MAP\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "stat = os.stat(test_file_path)\n",
        "\n",
        "from datetime import datetime\n",
        "m_time = datetime.fromtimestamp(stat.st_mtime).timestamp()\n",
        "a_time = datetime.fromtimestamp(stat.st_atime).timestamp()\n",
        "c_time = datetime.fromtimestamp(stat.st_ctime).timestamp()\n",
        "\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load final model & scaler\n",
        "import joblib\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlPSemxUUSq_",
        "outputId": "fe69d70d-2553-4f83-b7df-d9847e5ee6a6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: ⚠️ Infected (Ransomware)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import math\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/50.c'\n",
        "\n",
        "# Use your same calculate_entropy & FILE_TYPE_MAP\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "stat = os.stat(test_file_path)\n",
        "\n",
        "from datetime import datetime\n",
        "m_time = datetime.fromtimestamp(stat.st_mtime).timestamp()\n",
        "a_time = datetime.fromtimestamp(stat.st_atime).timestamp()\n",
        "c_time = datetime.fromtimestamp(stat.st_ctime).timestamp()\n",
        "\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load final model & scaler\n",
        "import joblib\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jUp3VZ8e8Lw",
        "outputId": "2bbdf26a-a292-4c71-b240-1d8135c8dd51"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Final training for Logistic Regression with Dataset 2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# ✅ Features for Dataset 2: entropy, file_type, size\n",
        "X = df[['entropy', 'file_type']]\n",
        "#X['size'] = X['size'] / 10_000_000  # scale size like before if not done yet\n",
        "y = df['label']\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Logistic Regression Model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model_dataset2_LR.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler_dataset2_LR.joblib')\n",
        "\n",
        "print(\"✅ Final Logistic Regression model and scaler saved for Dataset 2!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203a8ef3-d21a-4042-e423-b0e25d34e9db",
        "id": "F5yiVEJtbGJa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Logistic Regression model and scaler saved for Dataset 2!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type]]\n",
        "\n",
        "# Load Logistic Regression model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_LR.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_LR.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7fYMJp6caLR",
        "outputId": "c047ea6f-818b-4fa5-f3c9-8572c900790a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}