{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2DEXe4ENjAu4pQTqxX4fd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yms07/My-Project1/blob/main/TestingModel_UsingAES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVkBD3k6N63A",
        "outputId": "cbae4010-6be1-453c-e5da-9d4cf8c00046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# =====================================\n",
        "# STEP 0: Mount Google Drive\n",
        "# =====================================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Ransomware Detection Full Colab Notebook (Steps 4-6 + K-Fold CV)\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Paths\n",
        "base_path = '/content/drive/MyDrive/ransomware_data'\n",
        "plain_csv = f'{base_path}/features_plaintext.csv'\n",
        "infect_csv = f'{base_path}/features_infected.csv'\n",
        "\n",
        "# Load data\n",
        "plain_df = pd.read_csv(plain_csv)\n",
        "infect_df = pd.read_csv(infect_csv)\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([plain_df, infect_df], ignore_index=True)\n",
        "\n",
        "# Convert timestamps to numeric\n",
        "for col in ['modified_time', 'access_time', 'created_time']:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    df[col] = df[col].astype('int64') / 1e9\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "print(\"✅ Dataset loaded and cleaned\")\n",
        "\n",
        "# All models\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'MLP': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "def kfold_train_and_evaluate(X, y, label):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    print(f\"\\n🧪 K-Fold Evaluation for {label}:\")\n",
        "\n",
        "    for name, model in models.items():\n",
        "        acc_list, prec_list, rec_list, f1_list, auc_list = [], [], [], [], []\n",
        "\n",
        "        for train_idx, test_idx in skf.split(X_scaled, y):\n",
        "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "            model.fit(X_train, y_train)\n",
        "            y_pred = model.predict(X_test)\n",
        "            y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "            acc_list.append(accuracy_score(y_test, y_pred))\n",
        "            prec_list.append(precision_score(y_test, y_pred))\n",
        "            rec_list.append(recall_score(y_test, y_pred))\n",
        "            f1_list.append(f1_score(y_test, y_pred))\n",
        "            if y_prob is not None:\n",
        "                auc_list.append(roc_auc_score(y_test, y_prob))\n",
        "\n",
        "        avg_acc = sum(acc_list) / len(acc_list)\n",
        "        avg_prec = sum(prec_list) / len(prec_list)\n",
        "        avg_rec = sum(rec_list) / len(rec_list)\n",
        "        avg_f1 = sum(f1_list) / len(f1_list)\n",
        "        avg_auc = sum(auc_list) / len(auc_list) if auc_list else None\n",
        "\n",
        "        print(f\"\\n📊 Model: {name}\")\n",
        "        print(f\"Accuracy : {avg_acc:.4f}\")\n",
        "        print(f\"Precision: {avg_prec:.4f}\")\n",
        "        print(f\"Recall   : {avg_rec:.4f}\")\n",
        "        print(f\"F1 Score : {avg_f1:.4f}\")\n",
        "        print(f\"AUC      : {avg_auc:.4f}\" if avg_auc else \"AUC      : N/A\")\n",
        "\n",
        "# ===============================\n",
        "# Run for all 3 feature combinations\n",
        "# ===============================\n",
        "\n",
        "y = df['label']\n",
        "\n",
        "# Dataset 1: entropy + file_type\n",
        "X1 = df[['entropy', 'file_type']]\n",
        "kfold_train_and_evaluate(X1, y, \"Dataset 1 (entropy + file_type)\")\n",
        "\n",
        "# Dataset 2: entropy + file_type + size\n",
        "X2 = df[['entropy', 'file_type', 'size']]\n",
        "kfold_train_and_evaluate(X2, y, \"Dataset 2 (entropy + file_type + size)\")\n",
        "\n",
        "# Dataset 3: entropy + file_type + size + MAC times\n",
        "X3 = df[['entropy', 'file_type', 'size', 'modified_time', 'access_time', 'created_time']]\n",
        "kfold_train_and_evaluate(X3, y, \"Dataset 3 (entropy + file_type + size + MAC times)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFJPkoLuYQVl",
        "outputId": "1a9bc8b3-d933-4872-cc66-866cee2ede65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded and cleaned\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 1 (entropy + file_type):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 0.9950\n",
            "Precision: 0.9975\n",
            "Recall   : 0.9972\n",
            "F1 Score : 0.9974\n",
            "AUC      : 0.9984\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 0.9422\n",
            "Precision: 0.9422\n",
            "Recall   : 1.0000\n",
            "F1 Score : 0.9703\n",
            "AUC      : 0.9146\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 0.9944\n",
            "Precision: 0.9973\n",
            "Recall   : 0.9968\n",
            "F1 Score : 0.9970\n",
            "AUC      : 0.9764\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 0.9943\n",
            "Precision: 0.9972\n",
            "Recall   : 0.9968\n",
            "F1 Score : 0.9970\n",
            "AUC      : 0.9981\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 0.9952\n",
            "Precision: 0.9977\n",
            "Recall   : 0.9971\n",
            "F1 Score : 0.9974\n",
            "AUC      : 0.9995\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 0.9926\n",
            "Precision: 0.9984\n",
            "Recall   : 0.9938\n",
            "F1 Score : 0.9961\n",
            "AUC      : 0.9966\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 0.9937\n",
            "Precision: 0.9984\n",
            "Recall   : 0.9950\n",
            "F1 Score : 0.9967\n",
            "AUC      : 0.9994\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 2 (entropy + file_type + size):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 0.9961\n",
            "Precision: 0.9980\n",
            "Recall   : 0.9978\n",
            "F1 Score : 0.9979\n",
            "AUC      : 0.9977\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 0.9422\n",
            "Precision: 0.9422\n",
            "Recall   : 1.0000\n",
            "F1 Score : 0.9703\n",
            "AUC      : 0.9266\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 0.9982\n",
            "Precision: 0.9989\n",
            "Recall   : 0.9992\n",
            "F1 Score : 0.9990\n",
            "AUC      : 0.9909\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 0.9992\n",
            "Precision: 0.9998\n",
            "Recall   : 0.9994\n",
            "F1 Score : 0.9996\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 0.9983\n",
            "Precision: 0.9995\n",
            "Recall   : 0.9987\n",
            "F1 Score : 0.9991\n",
            "AUC      : 0.9999\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 0.9936\n",
            "Precision: 0.9983\n",
            "Recall   : 0.9949\n",
            "F1 Score : 0.9966\n",
            "AUC      : 0.9951\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 0.9936\n",
            "Precision: 0.9982\n",
            "Recall   : 0.9950\n",
            "F1 Score : 0.9966\n",
            "AUC      : 0.9988\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 3 (entropy + file_type + size + MAC times):\n",
            "\n",
            "📊 Model: KNN\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: SVM\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n",
            "\n",
            "📊 Model: MLP\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "AUC      : 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xYtd5RMuTC53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV29_0XqSBOv",
        "outputId": "e9bf9950-09f8-4708-93e6-42b3a3010c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WX_NwyqSSQv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Final training for RandomForest with Dataset 2\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# Features same as best Dataset 2\n",
        "X = df[['entropy', 'file_type', 'size']]\n",
        "y = df['label']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "print(\"✅ Final model and scaler saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwZD78BCUEeF",
        "outputId": "5cd19adc-aac0-4f4f-cc65-448c25b501c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final model and scaler saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import math\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/olecli32.dll'\n",
        "\n",
        "# Use your same calculate_entropy & FILE_TYPE_MAP\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "stat = os.stat(test_file_path)\n",
        "\n",
        "from datetime import datetime\n",
        "m_time = datetime.fromtimestamp(stat.st_mtime).timestamp()\n",
        "a_time = datetime.fromtimestamp(stat.st_atime).timestamp()\n",
        "c_time = datetime.fromtimestamp(stat.st_ctime).timestamp()\n",
        "\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load final model & scaler\n",
        "import joblib\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlPSemxUUSq_",
        "outputId": "2c0d995c-7322-4687-9cda-b2dd866a0bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "import math\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Use your same calculate_entropy & FILE_TYPE_MAP\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "stat = os.stat(test_file_path)\n",
        "\n",
        "from datetime import datetime\n",
        "m_time = datetime.fromtimestamp(stat.st_mtime).timestamp()\n",
        "a_time = datetime.fromtimestamp(stat.st_atime).timestamp()\n",
        "c_time = datetime.fromtimestamp(stat.st_ctime).timestamp()\n",
        "\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load final model & scaler\n",
        "import joblib\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jUp3VZ8e8Lw",
        "outputId": "e06083fc-4af2-441e-8bbc-bcc6a3b9a3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: ⚠️ Infected (Ransomware)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Final training for Decision Tree with Dataset 2\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# ✅ Features for Dataset 2: entropy, file_type, size\n",
        "X = df[['entropy', 'file_type', 'size']]\n",
        "X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n",
        "y = df['label']\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Decision Tree Model\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model_dataset2_DT.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler_dataset2_DT.joblib')\n",
        "\n",
        "print(\"✅ Final Decision Tree model and scaler saved for Dataset 2!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6SuyGpBjfoz",
        "outputId": "310a0f32-8d4f-480f-af7c-977278684fa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Decision Tree model and scaler saved for Dataset 2!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-2049032011.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load Decision Tree model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_DT.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_DT.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oItztEyjun6",
        "outputId": "e562f3c4-946e-4123-b2f1-7b4da6d80e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: ⚠️ Infected (Ransomware)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/50.c'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load Decision Tree model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_DT.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_DT.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3ShwisSj5GL",
        "outputId": "b1c3d944-67df-4974-cc06-f6616c4094e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Final training for SVM with Dataset 2\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# ✅ Features for Dataset 2: entropy, file_type, size\n",
        "X = df[['entropy', 'file_type', 'size']]\n",
        "X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n",
        "y = df['label']\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# SVM Model (enable probability for predict_proba)\n",
        "model = SVC(probability=True)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model_dataset2_SVM.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler_dataset2_SVM.joblib')\n",
        "\n",
        "print(\"✅ Final SVM model and scaler saved for Dataset 2!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-_LUfjukqSd",
        "outputId": "f57dce3b-7e09-43b6-9e5e-eb057519f51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-3488454417.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final SVM model and scaler saved for Dataset 2!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load SVM model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_SVM.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_SVM.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNj-XO93lJjB",
        "outputId": "ce2d5cdb-b8d8-420a-a91d-2ce0fc5cbc78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: ⚠️ Infected (Ransomware)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/50.c'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load SVM model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_SVM.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_SVM.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkD1oMColQAz",
        "outputId": "5a915bd0-73f8-4689-b569-41c19aa7dab4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Final training for MLP with Dataset 2\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "\n",
        "# ✅ Features for Dataset 2: entropy, file_type, size\n",
        "X = df[['entropy', 'file_type', 'size']]\n",
        "X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n",
        "y = df['label']\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# MLP Model (you can tune hidden_layer_sizes if needed)\n",
        "model = MLPClassifier(max_iter=1000, random_state=42)\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Save model & scaler\n",
        "joblib.dump(model, '/content/drive/MyDrive/ransomware_model_dataset2_MLP.joblib')\n",
        "joblib.dump(scaler, '/content/drive/MyDrive/ransomware_scaler_dataset2_MLP.joblib')\n",
        "\n",
        "print(\"✅ Final MLP model and scaler saved for Dataset 2!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVItMt9Vl7yN",
        "outputId": "fe16e618-ef1b-46b0-c0b1-310c133b5db1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-1508229968.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X['size'] = X['size'] / 10_000_000  # scale size (if not done before)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final MLP model and scaler saved for Dataset 2!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/aclui.dll'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load MLP model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_MLP.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_MLP.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8pXlMD1mBTw",
        "outputId": "88dbb650-36c4-49ce-91f1-28af8df93114"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: ⚠️ Infected (Ransomware)!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "from datetime import datetime\n",
        "import joblib\n",
        "\n",
        "def calculate_entropy(file_path):\n",
        "  try:\n",
        "    with open(file_path, 'rb') as f:\n",
        "      data = f.read()\n",
        "    if not data:\n",
        "      return 0.0\n",
        "    freq_list = [0] * 256\n",
        "    for b in data:\n",
        "      freq_list[b] += 1\n",
        "    entropy = 0.0\n",
        "    for freq in freq_list:\n",
        "      if freq > 0:\n",
        "        p = freq / len(data)\n",
        "        entropy -= p * math.log2(p)\n",
        "    return round(entropy, 4)\n",
        "  except:\n",
        "    return 0.0\n",
        "\n",
        "# Same file type map\n",
        "FILE_TYPE_MAP = {\n",
        "  'dll': 3, 'sys': 4, 'c': 13, 'cpp': 14, 'csv': 1, 'txt': 2,\n",
        "  'doc': 5, 'docx': 6, 'pdf': 7, 'ppt': 8, 'pptx': 9, 'xls': 10,\n",
        "  'xlsx': 11, 'html': 12, 'jpg': 15, 'zip': 16\n",
        "}\n",
        "\n",
        "# Example: New file path\n",
        "test_file_path = '/content/drive/MyDrive/test_files/50.c'\n",
        "\n",
        "# Extract features\n",
        "entropy = calculate_entropy(test_file_path)\n",
        "size = os.path.getsize(test_file_path) / 10_000_000  # scale like training\n",
        "ext = test_file_path.split('.')[-1].lower()\n",
        "file_type = FILE_TYPE_MAP.get(ext, 0)\n",
        "\n",
        "# ✅ Dataset 2: Only [entropy, file_type, size]\n",
        "X_new = [[entropy, file_type, size]]\n",
        "\n",
        "# Load MLP model & scaler\n",
        "model = joblib.load('/content/drive/MyDrive/ransomware_model_dataset2_MLP.joblib')\n",
        "scaler = joblib.load('/content/drive/MyDrive/ransomware_scaler_dataset2_MLP.joblib')\n",
        "\n",
        "X_scaled_new = scaler.transform(X_new)\n",
        "\n",
        "pred = model.predict(X_scaled_new)\n",
        "\n",
        "print(\"✅ Verdict:\", \"Safe (Plaintext)\" if pred[0] == 1 else \"⚠️ Infected (Ransomware)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZoX6JVfmJrE",
        "outputId": "cbb3be74-cc0d-4f33-fbaa-68b8a5f06649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Verdict: Safe (Plaintext)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# 📂 1) Import libraries\n",
        "# ==========================\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.base import clone\n",
        "\n",
        "# ==========================\n",
        "# 📂 2) Load data\n",
        "# ==========================\n",
        "# Paths\n",
        "base_path = '/content/drive/MyDrive/ransomware_data'\n",
        "plain_csv = f'{base_path}/features_plaintext.csv'\n",
        "infect_csv = f'{base_path}/features_infected.csv'\n",
        "\n",
        "# Load data\n",
        "plain_df = pd.read_csv(plain_csv)\n",
        "infect_df = pd.read_csv(infect_csv)\n",
        "\n",
        "# Combine datasets\n",
        "df = pd.concat([plain_df, infect_df], ignore_index=True)\n",
        "\n",
        "# Convert timestamps to numeric\n",
        "for col in ['modified_time', 'access_time', 'created_time']:\n",
        "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "    df[col] = df[col].astype('int64') / 1e9\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "print(\"✅ Dataset loaded and cleaned\")\n",
        "\n",
        "# ==========================\n",
        "# 📂 3) Models\n",
        "# ==========================\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'DecisionTree': DecisionTreeClassifier(),\n",
        "    'RandomForest': RandomForestClassifier(),\n",
        "    'GradientBoosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC(probability=True),\n",
        "    'MLP': MLPClassifier(max_iter=1000)\n",
        "}\n",
        "\n",
        "# ==========================\n",
        "# 📂 4) K-Fold CV Function\n",
        "# ==========================\n",
        "def kfold_train_and_evaluate(X, y, label):\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "    print(f\"\\n🧪 K-Fold Evaluation for {label}:\")\n",
        "\n",
        "    for name, model in models.items():\n",
        "        acc_list, prec_list, rec_list, f1_list, auc_list = [], [], [], [], []\n",
        "        acc_list_train, prec_list_train, rec_list_train, f1_list_train, auc_list_train = [], [], [], [], []\n",
        "\n",
        "        for train_idx, test_idx in skf.split(X_scaled, y):\n",
        "            X_train, X_test = X_scaled[train_idx], X_scaled[test_idx]\n",
        "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "            m = clone(model)\n",
        "            m.fit(X_train, y_train)\n",
        "\n",
        "            y_pred_test = m.predict(X_test)\n",
        "            y_pred_train = m.predict(X_train)\n",
        "\n",
        "            y_prob_test = m.predict_proba(X_test)[:, 1] if hasattr(m, \"predict_proba\") else None\n",
        "            y_prob_train = m.predict_proba(X_train)[:, 1] if hasattr(m, \"predict_proba\") else None\n",
        "\n",
        "            # Test scores\n",
        "            acc_list.append(accuracy_score(y_test, y_pred_test))\n",
        "            prec_list.append(precision_score(y_test, y_pred_test))\n",
        "            rec_list.append(recall_score(y_test, y_pred_test))\n",
        "            f1_list.append(f1_score(y_test, y_pred_test))\n",
        "            if y_prob_test is not None:\n",
        "                auc_list.append(roc_auc_score(y_test, y_prob_test))\n",
        "\n",
        "            # Train scores\n",
        "            acc_list_train.append(accuracy_score(y_train, y_pred_train))\n",
        "            prec_list_train.append(precision_score(y_train, y_pred_train))\n",
        "            rec_list_train.append(recall_score(y_train, y_pred_train))\n",
        "            f1_list_train.append(f1_score(y_train, y_pred_train))\n",
        "            if y_prob_train is not None:\n",
        "                auc_list_train.append(roc_auc_score(y_train, y_prob_train))\n",
        "\n",
        "        # Averages\n",
        "        avg_acc = sum(acc_list) / len(acc_list)\n",
        "        avg_prec = sum(prec_list) / len(prec_list)\n",
        "        avg_rec = sum(rec_list) / len(rec_list)\n",
        "        avg_f1 = sum(f1_list) / len(f1_list)\n",
        "        avg_auc = sum(auc_list) / len(auc_list) if auc_list else None\n",
        "\n",
        "        avg_acc_train = sum(acc_list_train) / len(acc_list_train)\n",
        "        avg_prec_train = sum(prec_list_train) / len(prec_list_train)\n",
        "        avg_rec_train = sum(rec_list_train) / len(rec_list_train)\n",
        "        avg_f1_train = sum(f1_list_train) / len(f1_list_train)\n",
        "        avg_auc_train = sum(auc_list_train) / len(auc_list_train) if auc_list_train else None\n",
        "\n",
        "        print(f\"\\n📊 Model: {name}\")\n",
        "        print(f\"Train Accuracy : {avg_acc_train:.4f} | Test Accuracy : {avg_acc:.4f} | Diff: {avg_acc_train - avg_acc:.4f}\")\n",
        "        print(f\"Train Precision: {avg_prec_train:.4f} | Test Precision: {avg_prec:.4f} | Diff: {avg_prec_train - avg_prec:.4f}\")\n",
        "        print(f\"Train Recall   : {avg_rec_train:.4f} | Test Recall   : {avg_rec:.4f} | Diff: {avg_rec_train - avg_rec:.4f}\")\n",
        "        print(f\"Train F1 Score : {avg_f1_train:.4f} | Test F1 Score : {avg_f1:.4f} | Diff: {avg_f1_train - avg_f1:.4f}\")\n",
        "        if avg_auc_train is not None and avg_auc is not None:\n",
        "            print(f\"Train AUC      : {avg_auc_train:.4f} | Test AUC      : {avg_auc:.4f} | Diff: {avg_auc_train - avg_auc:.4f}\")\n",
        "        else:\n",
        "            print(f\"AUC: N/A\")\n",
        "\n",
        "# ==========================\n",
        "# 📂 5) Run all 3 datasets\n",
        "# ==========================\n",
        "y = df['label']\n",
        "\n",
        "# Dataset 1: entropy + file_type\n",
        "X1 = df[['entropy', 'file_type']]\n",
        "kfold_train_and_evaluate(X1, y, \"Dataset 1 (entropy + file_type)\")\n",
        "\n",
        "# Dataset 2: entropy + file_type + size\n",
        "X2 = df[['entropy', 'file_type', 'size']]\n",
        "kfold_train_and_evaluate(X2, y, \"Dataset 2 (entropy + file_type + size)\")\n",
        "\n",
        "# Dataset 3: entropy + file_type + size + MAC times\n",
        "X3 = df[['entropy', 'file_type', 'size', 'modified_time', 'access_time', 'created_time']]\n",
        "kfold_train_and_evaluate(X3, y, \"Dataset 3 (entropy + file_type + size + MAC times)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZTrEDD1TGbG",
        "outputId": "dbf6adb1-855a-47dd-997f-3239f0440c08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded and cleaned\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 1 (entropy + file_type):\n",
            "\n",
            "📊 Model: KNN\n",
            "Train Accuracy : 0.9964 | Test Accuracy : 0.9950 | Diff: 0.0013\n",
            "Train Precision: 0.9983 | Test Precision: 0.9975 | Diff: 0.0007\n",
            "Train Recall   : 0.9979 | Test Recall   : 0.9972 | Diff: 0.0007\n",
            "Train F1 Score : 0.9981 | Test F1 Score : 0.9974 | Diff: 0.0007\n",
            "Train AUC      : 0.9998 | Test AUC      : 0.9984 | Diff: 0.0014\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Train Accuracy : 0.9422 | Test Accuracy : 0.9422 | Diff: -0.0000\n",
            "Train Precision: 0.9422 | Test Precision: 0.9422 | Diff: -0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 0.9703 | Test F1 Score : 0.9703 | Diff: 0.0000\n",
            "Train AUC      : 0.9156 | Test AUC      : 0.9146 | Diff: 0.0010\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Train Accuracy : 0.9991 | Test Accuracy : 0.9944 | Diff: 0.0048\n",
            "Train Precision: 1.0000 | Test Precision: 0.9973 | Diff: 0.0027\n",
            "Train Recall   : 0.9991 | Test Recall   : 0.9968 | Diff: 0.0024\n",
            "Train F1 Score : 0.9995 | Test F1 Score : 0.9970 | Diff: 0.0025\n",
            "Train AUC      : 1.0000 | Test AUC      : 0.9763 | Diff: 0.0237\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Train Accuracy : 0.9991 | Test Accuracy : 0.9943 | Diff: 0.0048\n",
            "Train Precision: 0.9998 | Test Precision: 0.9972 | Diff: 0.0026\n",
            "Train Recall   : 0.9993 | Test Recall   : 0.9968 | Diff: 0.0025\n",
            "Train F1 Score : 0.9995 | Test F1 Score : 0.9970 | Diff: 0.0026\n",
            "Train AUC      : 1.0000 | Test AUC      : 0.9984 | Diff: 0.0016\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Train Accuracy : 0.9961 | Test Accuracy : 0.9952 | Diff: 0.0010\n",
            "Train Precision: 0.9983 | Test Precision: 0.9977 | Diff: 0.0006\n",
            "Train Recall   : 0.9976 | Test Recall   : 0.9971 | Diff: 0.0005\n",
            "Train F1 Score : 0.9980 | Test F1 Score : 0.9974 | Diff: 0.0005\n",
            "Train AUC      : 0.9998 | Test AUC      : 0.9995 | Diff: 0.0003\n",
            "\n",
            "📊 Model: SVM\n",
            "Train Accuracy : 0.9927 | Test Accuracy : 0.9926 | Diff: 0.0000\n",
            "Train Precision: 0.9984 | Test Precision: 0.9984 | Diff: 0.0000\n",
            "Train Recall   : 0.9938 | Test Recall   : 0.9938 | Diff: 0.0000\n",
            "Train F1 Score : 0.9961 | Test F1 Score : 0.9961 | Diff: 0.0000\n",
            "Train AUC      : 0.9968 | Test AUC      : 0.9966 | Diff: 0.0001\n",
            "\n",
            "📊 Model: MLP\n",
            "Train Accuracy : 0.9937 | Test Accuracy : 0.9936 | Diff: 0.0001\n",
            "Train Precision: 0.9982 | Test Precision: 0.9982 | Diff: 0.0000\n",
            "Train Recall   : 0.9950 | Test Recall   : 0.9950 | Diff: 0.0000\n",
            "Train F1 Score : 0.9966 | Test F1 Score : 0.9966 | Diff: 0.0000\n",
            "Train AUC      : 0.9994 | Test AUC      : 0.9994 | Diff: 0.0000\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 2 (entropy + file_type + size):\n",
            "\n",
            "📊 Model: KNN\n",
            "Train Accuracy : 0.9973 | Test Accuracy : 0.9961 | Diff: 0.0012\n",
            "Train Precision: 0.9986 | Test Precision: 0.9980 | Diff: 0.0006\n",
            "Train Recall   : 0.9986 | Test Recall   : 0.9978 | Diff: 0.0008\n",
            "Train F1 Score : 0.9986 | Test F1 Score : 0.9979 | Diff: 0.0007\n",
            "Train AUC      : 0.9999 | Test AUC      : 0.9977 | Diff: 0.0022\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Train Accuracy : 0.9422 | Test Accuracy : 0.9422 | Diff: -0.0000\n",
            "Train Precision: 0.9422 | Test Precision: 0.9422 | Diff: -0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 0.9703 | Test F1 Score : 0.9703 | Diff: 0.0000\n",
            "Train AUC      : 0.9269 | Test AUC      : 0.9266 | Diff: 0.0003\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 0.9983 | Diff: 0.0017\n",
            "Train Precision: 1.0000 | Test Precision: 0.9991 | Diff: 0.0009\n",
            "Train Recall   : 1.0000 | Test Recall   : 0.9992 | Diff: 0.0008\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 0.9991 | Diff: 0.0009\n",
            "Train AUC      : 1.0000 | Test AUC      : 0.9921 | Diff: 0.0079\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 0.9992 | Diff: 0.0008\n",
            "Train Precision: 1.0000 | Test Precision: 0.9998 | Diff: 0.0002\n",
            "Train Recall   : 1.0000 | Test Recall   : 0.9994 | Diff: 0.0006\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 0.9996 | Diff: 0.0004\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Train Accuracy : 0.9994 | Test Accuracy : 0.9983 | Diff: 0.0011\n",
            "Train Precision: 1.0000 | Test Precision: 0.9995 | Diff: 0.0005\n",
            "Train Recall   : 0.9994 | Test Recall   : 0.9987 | Diff: 0.0007\n",
            "Train F1 Score : 0.9997 | Test F1 Score : 0.9991 | Diff: 0.0006\n",
            "Train AUC      : 1.0000 | Test AUC      : 0.9999 | Diff: 0.0001\n",
            "\n",
            "📊 Model: SVM\n",
            "Train Accuracy : 0.9937 | Test Accuracy : 0.9936 | Diff: 0.0001\n",
            "Train Precision: 0.9984 | Test Precision: 0.9983 | Diff: 0.0001\n",
            "Train Recall   : 0.9949 | Test Recall   : 0.9949 | Diff: 0.0000\n",
            "Train F1 Score : 0.9966 | Test F1 Score : 0.9966 | Diff: 0.0000\n",
            "Train AUC      : 0.9955 | Test AUC      : 0.9951 | Diff: 0.0005\n",
            "\n",
            "📊 Model: MLP\n",
            "Train Accuracy : 0.9937 | Test Accuracy : 0.9936 | Diff: 0.0001\n",
            "Train Precision: 0.9983 | Test Precision: 0.9982 | Diff: 0.0001\n",
            "Train Recall   : 0.9950 | Test Recall   : 0.9950 | Diff: 0.0000\n",
            "Train F1 Score : 0.9967 | Test F1 Score : 0.9966 | Diff: 0.0001\n",
            "Train AUC      : 0.9995 | Test AUC      : 0.9988 | Diff: 0.0006\n",
            "\n",
            "🧪 K-Fold Evaluation for Dataset 3 (entropy + file_type + size + MAC times):\n",
            "\n",
            "📊 Model: KNN\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: LogisticRegression\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: DecisionTree\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: RandomForest\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: GradientBoosting\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: SVM\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n",
            "\n",
            "📊 Model: MLP\n",
            "Train Accuracy : 1.0000 | Test Accuracy : 1.0000 | Diff: 0.0000\n",
            "Train Precision: 1.0000 | Test Precision: 1.0000 | Diff: 0.0000\n",
            "Train Recall   : 1.0000 | Test Recall   : 1.0000 | Diff: 0.0000\n",
            "Train F1 Score : 1.0000 | Test F1 Score : 1.0000 | Diff: 0.0000\n",
            "Train AUC      : 1.0000 | Test AUC      : 1.0000 | Diff: 0.0000\n"
          ]
        }
      ]
    }
  ]
}